{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "   _____                            _                __      ___     _                  _                        _ \n",
    "  / ____|                          | |               \\ \\    / (_)   (_)                | |                      | |\n",
    " | |     ___  _ __ ___  _ __  _   _| |_ ___ _ __      \\ \\  / / _ ___ _  ___  _ __      | |__   __ _ ___  ___  __| |\n",
    " | |    / _ \\| '_ ` _ \\| '_ \\| | | | __/ _ \\ '__|      \\ \\/ / | / __| |/ _ \\| '_ \\     | '_ \\ / _` / __|/ _ \\/ _` |\n",
    " | |___| (_) | | | | | | |_) | |_| | ||  __/ |          \\  /  | \\__ \\ | (_) | | | |    | |_) | (_| \\__ \\  __/ (_| |\n",
    "  \\_____\\___/|_| |_| |_| .__/ \\__,_|\\__\\___|_|           \\/   |_|___/_|\\___/|_| |_|    |_.__/ \\__,_|___/\\___|\\__,_|\n",
    "  _______              | | __  __                                                    _                             \n",
    " |__   __|             |_||  \\/  |                                                  | |                            \n",
    "    | |_ __ ___  ___      | \\  / | ___  __ _ ___ _   _ _ __ ___ _ __ ___   ___ _ __ | |_                           \n",
    "    | | '__/ _ \\/ _ \\     | |\\/| |/ _ \\/ _` / __| | | | '__/ _ \\ '_ ` _ \\ / _ \\ '_ \\| __|                          \n",
    "    | | | |  __/  __/     | |  | |  __/ (_| \\__ \\ |_| | | |  __/ | | | | |  __/ | | | |_                           \n",
    "    |_|_|  \\___|\\___|     |_|  |_|\\___|\\__,_|___/\\__,_|_|  \\___|_| |_| |_|\\___|_| |_|\\__|                          \n",
    "                                                                                                                   \n",
    "                                                                                                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from glob import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frame extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame extraction from video\n",
    "\n",
    "def extract_frames(video_path, output_folder = \"./assets/extracted\", capture_every_frame=30):\n",
    "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "\n",
    "    os.makedirs(f\"{output_folder}/{video_name}\", exist_ok=True)\n",
    "\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Total frames in {video_name}: {total_frames}\")\n",
    "\n",
    "    frames = 0\n",
    "\n",
    "    while total_frames > frames*capture_every_frame:\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, frames * capture_every_frame)\n",
    "        success, image = video.read()\n",
    "\n",
    "        # sometimes this fails, corrupt frames in vide? idk\n",
    "        if success:\n",
    "            cv2.imwrite(f\"./{output_folder}/{video_name}/{video_name}_{frames}.png\", image)\n",
    "\n",
    "        frames += 1\n",
    "\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames in calibration: 2995\n",
      "Total frames in eastbound_20240319: 18786\n",
      "Total frames in westbound_20240319: 12371\n"
     ]
    }
   ],
   "source": [
    "calibration_video = \"./assets/original/calibration.MP4\"\n",
    "eastbound_video   = \"./assets/original/eastbound_20240319.MP4\"\n",
    "westbound_video   = \"./assets/original/westbound_20240319.MP4\"\n",
    "\n",
    "\n",
    "extract_frames(calibration_video)\n",
    "extract_frames(eastbound_video)\n",
    "extract_frames(westbound_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_camera(calibration_images):\n",
    "    objp = np.zeros((6*8, 3), np.float32)\n",
    "    objp[:, :2] = np.mgrid[0:8, 0:6].T.reshape(-1, 2)\n",
    "\n",
    "    objpoints = []\n",
    "    imgpoints = []\n",
    "\n",
    "\n",
    "    for img_path in calibration_images:\n",
    "        img = cv2.imread(img_path)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (8, 6), None)\n",
    "\n",
    "        if ret:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "    return ret, mtx, dist, rvecs, tvecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_images = glob('./assets/extracted/calibration/*.png')\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = calibrate_camera(calibration_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undestortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort_images(images, output_loc=\"./assets/undestorted\"):\n",
    "    os.makedirs(f\"{output_loc}\", exist_ok=True)\n",
    "\n",
    "    for img_path in images:\n",
    "        img = cv2.imread(img_path)\n",
    "        frame_name = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        h,  w = img.shape[:2]\n",
    "        newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "\n",
    "        undistorted_image = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "        cv2.imwrite(f\"./{output_loc}/{frame_name}.png\", undistorted_image)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "westbound_images   = glob('./assets/extracted/westbound_20240319/*.png')\n",
    "eastbound_images   = glob('./assets/extracted/eastbound_20240319/*.png')\n",
    "\n",
    "undistort_images(westbound_images, output_loc=\"./assets/undestorted/westbound\")\n",
    "undistort_images(eastbound_images, output_loc=\"./assets/undestorted/eastbound\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://universe.roboflow.com/trees-sam/trees-detection-yac52/model/2\n",
    "# https://github.com/norlab-ulaval/PercepTreeV1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Triangulation and mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
