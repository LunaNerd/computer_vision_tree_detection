{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder_path = './assets/undistorted_05/eastbound'\n",
    "\n",
    "\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "def getNumber(x):\n",
    "    num_w_ext = x.split('_')[2]\n",
    "    num = num_w_ext.split('.')[0]\n",
    "    return num\n",
    "\n",
    "sorted_files = sorted(files, key=lambda x: int(getNumber(x)))\n",
    "\n",
    "# print(sorted_files)\n",
    "\n",
    "# points = [(1044, 784), (1439, 800), (1687, 1131), (229, 1034)]\n",
    "\n",
    "\n",
    "\n",
    "# matrix = [[-2.55742823e-01, -2.45586077e+00,  2.03742378e+03], [ 9.30304363e-02, -2.62394313e+00,  1.80508106e+03], [ 4.87713313e-05, -1.54852038e-03,  1.00000000e+00]]\n",
    "\n",
    "# matrix = [[-1.27785172e-01, -2.26968534e+00 , 1.73418419e+03],\n",
    "#  [ 1.71129072e-01 ,-4.44935587e+00  ,2.88934325e+03],\n",
    "#  [ 6.32873786e-05 ,-1.58006717e-03 , 1.00000000e+00]]\n",
    "\n",
    "# matrix = np.float32(matrix)\n",
    "src_points = np.float32([[1200,750], [1400,750], [2120,1515], [-1035, 1515]])\n",
    "dst_points = np.float32([\n",
    "    [1250,770],\n",
    "    [1450,770],\n",
    "    [1450, 1520],\n",
    "    [1250, 1520]\n",
    "])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "M_inv = cv2.getPerspectiveTransform(dst_points, src_points)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_images = []\n",
    "transformed_images = []\n",
    "\n",
    "for img_source in sorted_files:\n",
    "    print(img_source)\n",
    "    image = cv2.imread(f\"{folder_path}/{img_source}\")\n",
    "\n",
    "    transformed_image = cv2.warpPerspective(image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    normal_images.append(image)\n",
    "    transformed_images.append(transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(16, 4))\n",
    "colors = plt.cm.tab10.colors[:10]\n",
    "\n",
    "path = \"./assets/annotated_05/eastbound/\"\n",
    "\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "\n",
    "def update(frame):\n",
    "    print(frame)\n",
    "    x_limit = (-500, 6000)\n",
    "    y_limit = (-2000, 6000)\n",
    "\n",
    "    ax1.clear()\n",
    "    ax2.clear()\n",
    "    ax3.clear()\n",
    "\n",
    "    ax1.imshow(normal_images[frame])\n",
    "    ax2.imshow(transformed_images[frame])  # Display the current frame for video 2\n",
    "\n",
    "    name = sorted_files[frame].replace('png', 'json')\n",
    "\n",
    "    with open(path + name, 'r') as json_file:\n",
    "    # Load the JSON data\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    for index, point in enumerate(data[\"pred_keypoints\"]):\n",
    "        x = point[0][0]\n",
    "        # y = point[0][1]\n",
    "\n",
    "        y = data[\"pred_boxes\"][index][3]\n",
    "\n",
    "\n",
    "\n",
    "        # Define the point you want to transform\n",
    "        point = np.array([x, y])  # Example point at (50, 50)\n",
    "        point_original = point.reshape(-1, 1, 2)\n",
    "        transformed_point = cv2.perspectiveTransform(point_original, M)\n",
    "\n",
    "\n",
    "        # print(frame, transformed_point, transformed_point_a)\n",
    "\n",
    "        ax1.scatter(x, y, color=colors[index], s=50)\n",
    "        ax2.scatter(transformed_point[0][0][0], transformed_point[0][0][1], color=colors[index], s=50)\n",
    "        ax3.scatter(transformed_point[0][0][0], -transformed_point[0][0][1], color=colors[index], s=50)\n",
    "        ax4.scatter(transformed_point[0][0][0], -transformed_point[0][0][1] + (frame * 40), color='black', s=2)\n",
    "\n",
    "        # df.append({'X': transformed_point[0][0][0], 'Y': -transformed_point[0][0][1]}, ignore_index=True)\n",
    "\n",
    "        x_data.append(transformed_point[0][0][0])\n",
    "        y_data.append(-transformed_point[0][0][1] + (frame * 40))\n",
    "\n",
    "\n",
    "\n",
    "    ax3.set_xlim(x_limit)\n",
    "    ax3.set_ylim(y_limit)\n",
    "    \n",
    "\n",
    "    # ax4.set_xlim(x_limit)\n",
    "    # ax4.set_ylim(y_limit)\n",
    "\n",
    "    ax2.axis('off')  # Hide axes\n",
    "    ax1.axis('off')  # Hide axes\n",
    "    # ax3.figure.set_size_inches(5, 5)\n",
    "    return ax1, ax2\n",
    "\n",
    "\n",
    "# Create animations for both subplots\n",
    "ani = animation.FuncAnimation(fig, update, frames=len(normal_images), interval=150)\n",
    "# ani = animation.FuncAnimation(fig, update, frames=50, interval=150)\n",
    "\n",
    "HTML(ani.to_jshtml())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'X': x_data, 'Y': y_data})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = df[['X', 'Y']]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_scaled = X\n",
    "\n",
    "# Step 4: Perform DBSCAN clustering\n",
    "# You need to specify the epsilon (eps) parameter and the minimum samples (min_samples)\n",
    "# You might need to experiment with these parameters to get the desired clustering results\n",
    "eps = 100  # Adjust this based on your data\n",
    "min_samples = 5  # Adjust this based on your data\n",
    "dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "clusters = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "# Step 5: Analyze the clustering results\n",
    "# Add cluster labels to your DataFrame\n",
    "df['Cluster'] = clusters\n",
    "\n",
    "df_no_outlier = df[df['Cluster'] != -1]\n",
    "# df_no_outlier = df\n",
    "\n",
    "# Plot the clusters (assuming you have matplotlib installed)\n",
    "plt.scatter(df_no_outlier['X'], df_no_outlier['Y'], c=df_no_outlier['Cluster'], cmap='viridis', s=5)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.scatter(df_no_outlier['X'], df_no_outlier['Y'], c=df_no_outlier['Cluster'], cmap='viridis', s=5)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.gca().set_aspect(1)\n",
    "margin = 1000\n",
    "plt.xlim(min(df_no_outlier['X']) - margin, max(df_no_outlier['X']) + margin)\n",
    "plt.ylim(min(df_no_outlier['Y']) - margin, max(df_no_outlier['Y']) + margin)\n",
    "plt.show()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_mean = df_no_outlier.groupby('Cluster').mean()\n",
    "result_median = df_no_outlier.groupby('Cluster').median()\n",
    "\n",
    "\n",
    "plt.scatter(df['X'], df['Y'], c='black', s=1)\n",
    "plt.scatter(result_median['X'], result_median['Y'], c='red', s=20)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.scatter(result_mean['X'], result_mean['Y'], c='blue', s=4)\n",
    "plt.scatter(result_median['X'], result_median['Y'], c='red', s=4)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.scatter(result_mean['X'], result_mean['Y'], c='blue', s=4)\n",
    "plt.scatter(result_median['X'], result_median['Y'], c='red', s=4)\n",
    "plt.gca().set_aspect(1)\n",
    "margin = 1000  # Example margin value\n",
    "plt.xlim(min(result_median['X']) - margin, max(result_median['X']) + margin)\n",
    "plt.ylim(min(result_median['Y']) - margin, max(result_median['Y']) + margin)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "result_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(8, 4))\n",
    "colors = plt.cm.tab10.colors[:10]\n",
    "\n",
    "path = \"./assets/annotated_05/eastbound/\"\n",
    "\n",
    "x_data = []\n",
    "y_data = []\n",
    "\n",
    "\n",
    "# Function to update the image for video 2\n",
    "def update(frame):\n",
    "    print(frame)\n",
    "    x_limit = (-500, 6000)\n",
    "    y_limit = (-2000, 6000)\n",
    "\n",
    "    ax1.clear()\n",
    "    ax2.clear()\n",
    "\n",
    "    ax1.imshow(normal_images[frame])\n",
    "    ax2.imshow(transformed_images[frame])  # Display the current frame for video 2\n",
    "\n",
    "    name = sorted_files[frame].replace('png', 'json')\n",
    "\n",
    "    with open(path + name, 'r') as json_file:\n",
    "    # Load the JSON data\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    for index, point in enumerate(data[\"pred_keypoints\"]):\n",
    "        try:\n",
    "            x = point[0][0]\n",
    "            y = point[0][1]\n",
    "\n",
    "            point = np.array([x, y])  # Example point at (50, 50)\n",
    "            point_original = point.reshape(-1, 1, 2)\n",
    "            transformed_point = cv2.perspectiveTransform(point_original, M)\n",
    "\n",
    "            transformed_x = transformed_point[0][0][0]\n",
    "            transformed_y = -transformed_point[0][0][1] + (frame * 40)\n",
    "\n",
    "\n",
    "            result = df_no_outlier[(df_no_outlier['X'] == transformed_x) & (df_no_outlier['Y'] == transformed_y)]\n",
    "            if len(result) >= 1:\n",
    "                first_result = result.iloc[0]\n",
    "\n",
    "                cluster_id = first_result['Cluster']\n",
    "\n",
    "                first_test_df = result_median.iloc[int(cluster_id)]\n",
    "\n",
    "\n",
    "                x_median = first_test_df['X']\n",
    "                y_median = -(first_test_df['Y'] - (frame * 40))\n",
    "\n",
    "\n",
    "\n",
    "                point_ab = np.array([x_median, y_median])\n",
    "                point_original_ab = point_ab.reshape(-1, 1, 2)\n",
    "                de_transformed_point = cv2.perspectiveTransform(point_original_ab, M_inv)\n",
    "\n",
    "                test = colors[int(cluster_id % 10)]\n",
    "\n",
    "                ax1.scatter(x, y, color=test, s=10)\n",
    "                ax1.scatter(de_transformed_point[0][0][0], de_transformed_point[0][0][1], color=\"red\", s=50)\n",
    "                ax2.scatter(x_median, y_median, color=\"red\", s=50)\n",
    "                ax2.scatter(transformed_point[0][0][0], transformed_point[0][0][1], color=test, s=10)\n",
    "            # print(test)\n",
    "\n",
    "            # colors_cmap = [(0, 0, 0, 0), test]\n",
    "            # cmap = LinearSegmentedColormap.from_list('Custom', colors_cmap, len(colors_cmap))\n",
    "\n",
    "            # mask = masks[index]\n",
    "\n",
    "            # ax1.imshow(mask, cmap=cmap, interpolation='nearest', alpha=1)\n",
    "        except Exception as e:\n",
    "            print(\"An unexpected error occurred:\", e)\n",
    "\n",
    "\n",
    "    ax2.axis('off')  # Hide axes\n",
    "    ax1.axis('off')  # Hide axes\n",
    "    # ax3.figure.set_size_inches(5, 5)\n",
    "    return ax1, ax2\n",
    "\n",
    "\n",
    "# Create animations for both subplots\n",
    "ani = animation.FuncAnimation(fig, update, frames=len(normal_images), interval=150)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(8, 4))\n",
    "\n",
    "def update(frame):\n",
    "    ax1.clear()\n",
    "    ax2.clear()\n",
    "\n",
    "    ax2.imshow(normal_images[frame])\n",
    "\n",
    "    shape = np.array(normal_images[frame]).shape\n",
    "\n",
    "    height = shape[0]\n",
    "    width = shape[1]\n",
    "\n",
    "    cam_pos = np.array([width/2, height])\n",
    "\n",
    "    cam_pos_reshaped = cam_pos.reshape(-1, 1, 2)\n",
    "\n",
    "    transformed_cam_pos = cv2.perspectiveTransform(cam_pos_reshaped, M)\n",
    "\n",
    "    ax1.scatter(result_median['X'], result_median['Y'], c='red', s=4)\n",
    "    ax1.scatter(transformed_cam_pos[0][0][0], - transformed_cam_pos[0][0][1] + (frame*40), color=\"blue\", s=50)\n",
    "    \n",
    "    ax2.axis('off')\n",
    "    return ax1, ax2\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=len(normal_images), interval=150)\n",
    "\n",
    "HTML(ani.to_jshtml())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(8, 4))\n",
    "colors = plt.cm.tab10.colors[:10]\n",
    "\n",
    "path = \"./assets/annotated_05/eastbound/\"\n",
    "\n",
    "cluster_list = []\n",
    "widths  = []\n",
    "\n",
    "# Function to update the image for video 2\n",
    "def update(frame):\n",
    "    print(frame)\n",
    "    x_limit = (-500, 6000)\n",
    "    y_limit = (-2000, 6000)\n",
    "\n",
    "    ax1.clear()\n",
    "    ax2.clear()\n",
    "\n",
    "    ax1.imshow(normal_images[frame])\n",
    "    ax2.imshow(transformed_images[frame])  # Display the current frame for video 2\n",
    "\n",
    "    name = sorted_files[frame].replace('png', 'json')\n",
    "\n",
    "    with open(path + name, 'r') as json_file:\n",
    "    # Load the JSON data\n",
    "        data = json.load(json_file)\n",
    "\n",
    "    for index, point in enumerate(data[\"pred_keypoints\"]):\n",
    "        try:\n",
    "            x = point[0][0]\n",
    "            y = point[0][1]\n",
    "\n",
    "            left_x = point[1][0]\n",
    "            left_y = point[1][1]\n",
    "\n",
    "            right_x = point[2][0]\n",
    "            right_y = point[2][1]\n",
    "\n",
    "\n",
    "            left_point = np.array([left_x, left_y])\n",
    "            left_point_o = left_point.reshape(-1, 1, 2)\n",
    "            transformed_left_point = cv2.perspectiveTransform(left_point_o, M)\n",
    "\n",
    "            right_point = np.array([right_x, right_y])\n",
    "            right_point_o = right_point.reshape(-1, 1, 2)\n",
    "            transformed_right_point = cv2.perspectiveTransform(right_point_o, M)\n",
    "\n",
    "            point = np.array([x, y])\n",
    "            point_original = point.reshape(-1, 1, 2)\n",
    "            transformed_point = cv2.perspectiveTransform(point_original, M)\n",
    "\n",
    "            transformed_x = transformed_point[0][0][0]\n",
    "            transformed_y = -transformed_point[0][0][1] + (frame * 40)\n",
    "\n",
    "            ax1.scatter(x, y, color=\"white\", s=5)\n",
    "            ax1.scatter(left_x, left_y, color=\"blue\", s=5)\n",
    "            ax1.scatter(right_x, right_y, color=\"red\", s=5)\n",
    "\n",
    "            ax2.scatter(transformed_left_point[0][0][0], transformed_left_point[0][0][1], color=\"blue\", s=5)\n",
    "            ax2.scatter(transformed_right_point[0][0][0], transformed_right_point[0][0][1], color=\"red\", s=5)\n",
    "\n",
    "            euclidean_distance = math.sqrt((transformed_left_point[0][0][0] - transformed_right_point[0][0][0])**2 + (transformed_left_point[0][0][1] - transformed_right_point[0][0][1])**2)\n",
    "\n",
    "            print(euclidean_distance)\n",
    "\n",
    "            result = df_no_outlier[(df_no_outlier['X'] == transformed_x) & (df_no_outlier['Y'] == transformed_y)]\n",
    "            if len(result) >= 1:\n",
    "                first_result = result.iloc[0]\n",
    "\n",
    "                cluster_id = first_result['Cluster']\n",
    "\n",
    "                cluster_list.append(int(cluster_id))\n",
    "                widths.append(euclidean_distance)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"An unexpected error occurred:\", e)\n",
    "\n",
    "    \n",
    "\n",
    "    ax2.axis('off')  # Hide axes\n",
    "    ax1.axis('off')  # Hide axes\n",
    "    return ax1, ax2\n",
    "\n",
    "\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=len(normal_images), interval=150)\n",
    "\n",
    "# ani = animation.FuncAnimation(fig, update, frames=5, interval=150)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_width_trees = pd.DataFrame({'Cluster': cluster_list, 'Width_px': widths})\n",
    "\n",
    "df_width_trees_median = df_width_trees.groupby('Cluster').median()\n",
    "\n",
    "df_width_trees_in_cm = df_width_trees_median.assign(Width_cm=df_width_trees_median['Width_px'] * 2)\n",
    "\n",
    "df_trees = result_median.merge(df_width_trees_in_cm, left_on='Cluster', right_on='Cluster')\n",
    "\n",
    "df_trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_trees['X'], df_trees['Y'], c='brown', s=df_trees['Width_px'])\n",
    "plt.gca().set_aspect(1)\n",
    "\n",
    "margin = 1000\n",
    "plt.xlim(min(df_trees['X']) - margin, max(df_trees['X']) + margin)\n",
    "plt.ylim(min(df_trees['Y']) - margin, max(df_trees['Y']) + margin)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_1 = \"assets/undistorted_05/eastbound/eastbound_20240319_07816.png\"\n",
    "im_2 = \"assets/undistorted_05/eastbound/eastbound_20240319_07821.png\"\n",
    "\n",
    "\n",
    "img1 = cv2.imread(im_1, cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread(im_2, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Create SIFT detector\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Detect keypoints and compute descriptors\n",
    "keypoints1, descriptors1 = sift.detectAndCompute(img1, None)\n",
    "keypoints2, descriptors2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "# Define FLANN parameters for descriptor matching\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)\n",
    "\n",
    "# Create FLANN matcher\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "# Match descriptors\n",
    "matches = flann.knnMatch(descriptors1, descriptors2, k=2)\n",
    "\n",
    "# Lowe's ratio test\n",
    "good_matches = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.7 * n.distance:\n",
    "        good_matches.append(m)\n",
    "\n",
    "# Limit matches for better visualization\n",
    "if len(good_matches) > 100:\n",
    "    limited_matches = random.sample(good_matches, 100)\n",
    "\n",
    "# Draw matches\n",
    "img_matches_full = cv2.drawMatches(img1, keypoints1, img2, keypoints2, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "img_matches_limited = cv2.drawMatches(img1, keypoints1, img2, keypoints2, limited_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(18, 9))\n",
    "plt.imshow(cv2.cvtColor(img_matches_limited, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(18, 9))\n",
    "plt.imshow(cv2.cvtColor(img_matches_full, cv2.COLOR_BGR2RGB))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# im_1 = \"assets/undistorted_05/eastbound/eastbound_20240319_07816.png\"\n",
    "# im_2 = \"assets/undistorted_05/eastbound/eastbound_20240319_07821.png\"\n",
    "\n",
    "img1 = normal_images[0]\n",
    "img2 = normal_images[1]\n",
    "\n",
    "\n",
    "match = good_matches[100]\n",
    "\n",
    "query_idx = match.queryIdx  # Index of the matched keypoint in the query set\n",
    "train_idx = match.trainIdx  # Index of the matched keypoint in the train set\n",
    "\n",
    "# Get the coordinates of the matched keypoints using their indices\n",
    "query_keypoint = keypoints1[query_idx]  # Assuming 'query_keypoints' is a list of keypoints in the query image\n",
    "train_keypoint = keypoints2[train_idx]  # Assuming 'train_keypoints' is a list of keypoints in the train image\n",
    "\n",
    "# Extract the (x, y) coordinates of the matched keypoints\n",
    "query_x, query_y = query_keypoint.pt\n",
    "train_x, train_y = train_keypoint.pt\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.imshow(img1)\n",
    "plt.scatter(query_x, query_y, color=\"red\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.imshow(img2)\n",
    "plt.scatter(train_x, train_y, color=\"red\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_a = np.array([query_x, query_y])\n",
    "point_original_a = point_a.reshape(-1, 1, 2)\n",
    "transformed_point_a = cv2.perspectiveTransform(point_original_a, M)\n",
    "\n",
    "\n",
    "point_b = np.array([train_x, train_y])\n",
    "point_original_b = point_b.reshape(-1, 1, 2)\n",
    "transformed_point_b = cv2.perspectiveTransform(point_original_b, M)\n",
    "\n",
    "img1_trans = transformed_images[0]\n",
    "img2_trans = transformed_images[1]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.imshow(img1_trans)\n",
    "plt.scatter(transformed_point_a[0][0][0], transformed_point_a[0][0][1], color=\"red\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.imshow(img2_trans)\n",
    "plt.scatter(transformed_point_b[0][0][0], transformed_point_b[0][0][1], color=\"red\")\n",
    "# plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transformed_point_a)\n",
    "print(transformed_point_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_diff = transformed_point_b[0][0][0] - transformed_point_a[0][0][0]\n",
    "\n",
    "y_diff = transformed_point_b[0][0][1] - transformed_point_a[0][0][1]\n",
    "\n",
    "print(x_diff, y_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_diff_list = []\n",
    "y_diff_list = []\n",
    "\n",
    "for match in good_matches:\n",
    "    query_idx = match.queryIdx  # Index of the matched keypoint in the query set\n",
    "    train_idx = match.trainIdx  # Index of the matched keypoint in the train set\n",
    "\n",
    "    # Get the coordinates of the matched keypoints using their indices\n",
    "    query_keypoint = keypoints1[query_idx]  # Assuming 'query_keypoints' is a list of keypoints in the query image\n",
    "    train_keypoint = keypoints2[train_idx]  # Assuming 'train_keypoints' is a list of keypoints in the train image\n",
    "\n",
    "    # Extract the (x, y) coordinates of the matched keypoints\n",
    "    query_x, query_y = query_keypoint.pt\n",
    "    train_x, train_y = train_keypoint.pt\n",
    "\n",
    "    point_a = np.array([query_x, query_y])\n",
    "    point_original_a = point_a.reshape(-1, 1, 2)\n",
    "    transformed_point_a = cv2.perspectiveTransform(point_original_a, M)\n",
    "\n",
    "\n",
    "    point_b = np.array([train_x, train_y])\n",
    "    point_original_b = point_b.reshape(-1, 1, 2)\n",
    "    transformed_point_b = cv2.perspectiveTransform(point_original_b, M)\n",
    "\n",
    "    if((transformed_point_b[0][0][1] < 1520 or transformed_point_a[0][0][1] < 1520) and (transformed_point_b[0][0][1] > 0 or transformed_point_a[0][0][1] > 0) and (transformed_point_b[0][0][0] < 2560 or transformed_point_a[0][0][0] < 2560) and (transformed_point_b[0][0][0] > 0 or transformed_point_a[0][0][0] > 0) ):\n",
    "        img1_trans = transformed_images[0]\n",
    "        img2_trans = transformed_images[1]\n",
    "\n",
    "        x_diff = transformed_point_b[0][0][0] - transformed_point_a[0][0][0]\n",
    "\n",
    "        y_diff = transformed_point_b[0][0][1] - transformed_point_a[0][0][1]\n",
    "\n",
    "        print(x_diff, y_diff)\n",
    "\n",
    "\n",
    "        x_diff_list.append(x_diff)\n",
    "        y_diff_list.append(y_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "mean_x = statistics.mean(x_diff_list)\n",
    "mean_y = statistics.mean(y_diff_list)\n",
    "\n",
    "print(mean_x, mean_y)\n",
    "\n",
    "median_x = statistics.median(x_diff_list)\n",
    "median_y = statistics.median(y_diff_list)\n",
    "\n",
    "print(median_x, median_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
